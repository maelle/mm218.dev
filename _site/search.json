{
  "articles": [
    {
      "path": "index.html",
      "title": "Machine Learning Concepts and Applications",
      "description": "Slides, notes, and syllabus for FOR 796.\n",
      "author": [],
      "contents": "\nCourse Title and Instructor\nTitle: FOR 796: Machine Learning Concepts and ApplicationsTime and Place: Wednesday 2:15-3:10, Bray 300\nInstructor: Mike MahoneyEmail: mike.mahoney.218@gmail.comOffice Hours: Tuesday 11:30-12:30 (Baker 231), or by appointment\nCourse Description\nPrediction has taken over the world. Whether it’s predicting how species will adapt to a changing climate, which plant cultivars will hold their own against non-native diseases, or what pair of pants a customer is most likely to buy, prediction – and the algorithms built to predict – have come to dominate how we work and live in an incredibly short span of time. These predictive methods have seen their popularity skyrocket throughout the sciences in recent years, as it becomes increasingly important to not just understand how systems work but to communicate how they might respond to human activity moving forward.\nThe algorithms developed to enable all this prediction – referred to as “pure prediction algorithms” or, more loosely, “machine learning” – have seen massive success across domains. But this success comes at the cost of complexity, and implementing these techniques requires new tools and a different mindset than traditional statistical modeling as taught to most professionals.\nThis course attempts to help bridge that gap, guiding students through several of the most common machine learning approaches at a conceptual level with a focus on applications in R. Topics include the random forest and gradient boosting machine algorithms as well as cross validation and loss functions.\nCourse Structure\nEach week there will be a handout to read before class. You are encouraged to type the code from the handouts into your own R session, in order to develop familiarity with the syntax and develop muscle memory for common tasks.\nClass time on Wednesday will be a discussion format, dedicated to answering any questions from the reading. Office hours will be available weekly to help debug code problems or answer more specific questions.\nThe course culminates in a final project where students apply concepts from the course to a data set of their choosing. The final week of class will be spent presenting results from these projects.\nLearning Objectives\nBy the end of this course, students will be able to:\nImplement common supervised learning algorithms in R to make predictions against well-formed data sets.\nUse accepted hyperparameter tuning approaches to improve model fits across multiple algorithms.\nExplain how to assess predictive models, both throughout the iteration process and as a final product.\nPrerequisites\nStudents must have some familiarity with the R language, including defining functions, managing objects, controlling the flow of a program (e.g. if/else statements and for-loops), wrangling data in data frames, fitting linear models (i.e., the lm function) and other basic tasks.\nAn introductory stats course is recommended.\nTextbooks and Materials\nThis class draws heavily from materials presented in the following two books. Both books are freely available online and you do not need to purchase a physical copy of either book to succeed in this class; there are no assigned readings from these books.\nBradley Boehmke and Brandon Greenwell. (2020). Hands on Machine Learning with R. CRC Press. Available online at https://bradleyboehmke.github.io/HOML/ .\nBradley Efron and Trevor Hastie. (2016). Computer Age Statistical Inference. Cambridge University Press. Available online at https://web.stanford.edu/~hastie/CASI_files/PDF/casi.pdf .\nIn addition, I highly recommend the book An Introduction to Statistical Learning. While not used directly in this course, this book is potentially “the” ML textbook, and provides a comprehensible introduction to ML methods. This book is also available freely online; a citation is:\nGareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani. (2021). An Introduction to Statistical Learning with Applications in R. Springer Texts, second edition. Available online at https://www.statlearning.com/\nStudents will need to have access to a computer they are able to install R packages on.\nGrading\nGrades will be assigned based upon the final project. There are no other assignments in this course.\nStudents with Learning and Physical Disabilities\nSUNY-ESF works with the Office of Disability Services (ODS) at Syracuse University, who is responsible for coordinating disability-related accommodations. Students can contact ODS at 804 University Avenue- Room 309, 315-443-4498 to schedule an appointment and discuss their needs and the process for requesting accommodations. Students may also contact the ESF Office of Student Affairs, 110 Bray Hall, 315-470-6660 for assistance with the process. To learn more about ODS, visit http://disabilityservices.syr.edu. Students who attempt to use accommodations without advance notice to faculty will be referred to the ESF Office of the Dean for Student Affairs. Since accommodations may require early planning and generally are not provided retroactively, please contact ODS as soon as possible.\nAcademic Dishonesty\nAcademic dishonesty is a breach of trust between a student, one’s fellow students, or the instructor(s). By registering for courses at ESF you acknowledge your awareness of the ESF Code of Student Conduct (http://www.esf.edu/students/handbook/StudentHB.05.pdf ), in particular academic dishonesty includes but is not limited to plagiarism and cheating, and other forms of academic misconduct. The Academic Integrity Handbook contains further information and guidance (http://www.esf.edu/students/integrity/). Infractions of the academic integrity code may lead to academic penalties as per the ESF Grading Policy (http://www.esf.edu/provost/policies/documents/GradingPolicy.11.12.2013.pdf).\nInclusive Excellence Statement\nAs an institution, we embrace inclusive excellence and the strengths of a diverse and inclusive community. During classroom discussions, we may be challenged by ideas different from our lived experiences and cultures. Understanding individual differences and broader social differences will deepen our understanding of each other and the world around us. In this course, all people (including but not limited to, people of all races, ethnicities, sexual orientation, gender, gender identity and expression, students undergoing transition, religions, ages, abilities, socioeconomic backgrounds, veteran status, regions and nationalities, intellectual perspectives and political persuasion) are strongly encouraged to respectfully share their unique perspectives and experiences. This statement is intended to help cultivate a respectful environment, and it should not be used in a way that limits expression or restricts academic freedom at ESF.\n\n\n\n",
      "last_modified": "2021-09-02T22:06:56-04:00"
    },
    {
      "path": "schedule.html",
      "title": "Schedule",
      "description": "Schedule of topics for FOR 796: Machine Learning Concepts and Applications\n",
      "author": [],
      "contents": "\n\n\nWeek\n\n\nTopic\n\n\n1\n\n\nPrediction, Estimation, and Attribution\n\n\n2\n\n\nRegression\n\n\n3\n\n\nClassification\n\n\n4\n\n\nClassification with imbalanced classes\n\n\n5\n\n\nDecision Trees\n\n\n6\n\n\nRandom Forests\n\n\n7\n\n\nHyperparameters and Model Tuning\n\n\n8\n\n\nGradient Boosting Machines\n\n\n9\n\n\nStochastic GBMs and Stacked Ensembles\n\n\n10\n\n\nk-Nearest Neighbors\n\n\n11\n\n\nSupport Vector Machines (as time allows)\n\n\n12-13\n\n\nProject Work\n\n\n14\n\n\nPresentations\n\n\nCourse Structure\nEach week there will be a handout to read before class. You are encouraged to type the code from the handouts into your own R session, in order to develop familiarity with the syntax and develop muscle memory for common tasks.\nClass time on Wednesday will be a discussion format, dedicated to answering any questions from the reading. Office hours will be available weekly to help debug code problems or answer more specific questions.\nFinal Project\nThe primary assignment for this class is a single project where you’ll apply the techniques from this course to a data set of your choosing.\nThe last week of the semester you’ll hand in two files – one containing the code used in the course of your project, the other a short report about the question you set out to answer, the methods you used, your results, and some reflection on what went well and what you’d change to make your models better. You’ll also give a five-minute presentation on your project during the final class session.\nA rubric for this project will be made available during the semester.\n\n\n\n",
      "last_modified": "2021-09-02T22:06:57-04:00"
    }
  ],
  "collections": []
}
